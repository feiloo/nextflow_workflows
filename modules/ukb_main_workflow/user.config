manifest {
  homePage = 'https://github.com/feiloo/ngs_pipeline'
  description = 'nextflow pipeline for somatic ngs analysis on tumor-normal wgs'
  mainScript = 'main.nf'
  version = '0.1.2'
}


nextflow.enable.strict = true
nextflow.enable.moduleBinaries = true
nextflow.enable.dsl = 2
workDir = "$NEXTFLOW_WORKDIR_CUSTOM"
offline = true
cleanup = false


// create unique workflow ids through timestamps
// the ids are used for structured outputs
import java.time.Instant
Instant inst = Instant.now()
workflow_id = inst.toString()

// by default, give every tool all processors, in case they use/benefit from them
// set different values when running non-locally, see profile below
//default_cpus = Runtime.runtime.availableProcessors()
default_cpus = 8
// the runtime.maxMemory is 1/4 of total ram, bc thats what the java runtime uses
//executor.memory = 0.8 * 4 * Runtime.runtime.maxMemory()
default_memory = "56.GB"

// profiles for are mutually exclusive for simplicity
// when needing a combination or different profile, just add it as its own profile here
// some example profiles:
profiles {
  standard {
    // local, single-node, dependencies via conda

    // deactivate publishing by default, so we dont spam outputs and waste storage
    // set default resources for small unimportant processes. (overwritten by process directives)
    process {
      publishDir = ["enabled":false]
      cpus = "${default_cpus}"
      memory = "${default_memory}"
      time = 14.h
      executor = 'slurm'
      //scratch = "$NEXTFLOW_SCRATCH_DIR"
    }
    conda {
      enabled = true
      // set to .cache to keep the conda cache when wiping the nextflow_workdir
      //conda.cacheDir = "/.cache/nextflow_conda_cache"
    }
  }

  fully_native {
    // local, single-node, dependencies must be installed locally and be on PATH env-var

    // deactivate publishing by default, so we dont spam outputs and waste storage
    // set default resources for small unimportant processes. (overwritten by process directives)
    process {
      publishDir = ["enabled":false]
      withName: '.*' {
              cpus = "${default_cpus}"
              memory = "${default_memory}"
      }
    }
  }


  local_nas_workdir {
    // local, single-node, conda, use copy for staging for loading data from nas-filesystems
    // deactivate publishing by default, so we dont spam outputs and waste storage
    // set default resources for small unimportant processes. (overwritten by process directives)
    process {
      publishDir = ["enabled":false]
      withName: '.*' {
              cpus = "${default_cpus}"
              memory = "${default_memory}"
      }
      // nas filesystems dont support symlinks, therefore use scratch and stage files through copying
      stageInMode = 'copy'
      stageOutMode = 'copy'
      // use local scratch for fast io and avoid symlink issues
      scratch = '/scratch'
    }

    conda {
      enabled = true
      // set to .cache to keep the conda cache when wiping the nextflow_workdir
      conda.cacheDir = "$HOME/.cache/nextflow_conda_cache"
    }
  }

  hpc_localstorage {
    // run multinode with slurm and conda

    // set default resources for small unimportant processes. (overwritten by process directives)
    process {
      publishDir = ["enabled":false]
      withName: '.*' {
              cpus = 8
              memory = "${default_memory}"
      }
      // nas filesystems dont support symlinks, therefore use scratch and stage files through copying
      scratch = '/scratch'
      executor = 'slurm'
    }
    conda {
      enabled = true
      // set to .cache to keep the conda cache when wiping the nextflow_workdir
      conda.cacheDir = "$HOME/.cache/nextflow_conda_cache"
    }
  }

  hpc_nas {
    // run multinode with slurm and conda and load data from nas

    // set default resources for small unimportant processes. (overwritten by process directives)
    process {
      publishDir = ["enabled":false]
      withName: '.*' {
              cpus = 8
              memory = "${default_memory}"
      }
      // nas filesystems dont support symlinks, therefore use scratch and stage files through copying
      stageInMode = 'copy'
      stageOutMode = 'copy'
      scratch = '/scratch'
      executor = 'slurm'
    }
    conda {
      enabled = true
      // set to .cache to keep the conda cache when wiping the nextflow_workdir
      conda.cacheDir = "$HOME/.cache/nextflow_conda_cache"
    }
  }
}

includeConfig "$NEXTFLOW_MODULES/variantinterpretation/nextflow.config"

params {
  // general input-output params
  output_dir = "$NEXTFLOW_OUTPUTDIR_CUSTOM/${workflow_id}"
  outdir = "$NEXTFLOW_OUTPUTDIR_CUSTOM/${workflow_id}"
  workdir = "$NEXTFLOW_WORKDIR_CUSTOM"
  workflow_run_id = "${workflow_id}"


  // full paths, to where inputs and outputs should be moved to on the network attached storage
  nas_import_dir = "$NAS_IMPORT_DIR"
  nas_export_dir = "$NAS_EXPORT_DIR"

  // references and other data
  reference_data = "$NGS_REFERENCE_DIR/arriba_reference/GRCh38+GENCODE38/"

  // gatk reference genome
  refgenome = "$NGS_REFERENCE_DIR/sarek_reference/gatk_grch38/Homo_sapiens/GATK/GRCh38/Sequence/WholeGenomeFasta/Homo_sapiens_assembly38.fasta"

  //gatk intervals
  intervals = "$NGS_REFERENCE_DIR/sarek_reference/gatk_grch38/Homo_sapiens/GATK/GRCh38/Annotation/intervals/wgs_calling_regions_noseconds.hg38.bed"

  //gatk panel of normals
  panel_of_normals = "$NGS_REFERENCE_DIR/sarek_reference/gatk_grch38/Homo_sapiens/GATK/GRCh38/Annotation/GATKBundle/1000g_pon.hg38.vcf.gz"

  // germline resource (gnomad)
  germline_resource = "$NGS_REFERENCE_DIR/sarek_reference/gatk_grch38/Homo_sapiens/GATK/GRCh38/Annotation/GATKBundle/af-only-gnomad.hg38.vcf.gz"

  // dbsnp reference for gatk recalibration
  known_sites = "$NGS_REFERENCE_DIR/sarek_reference/gatk_grch38/Homo_sapiens/GATK/GRCh38/Annotation/GATKBundle/dbsnp_146.hg38.vcf.gz"

  // clc tool specific params
  clc_workflow_name = '"name_of_clc_workflow"'

  // full filepaths to the import export directories on the clc server master node
  clc_import_dir = ''
  clc_export_dir = ''
  clc_destdir = ''

  // pancancer scripts variables
  vep_refgenome = "$NGS_REFERENCE_DIR/vep_fasta/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz"

  // cio variantinterpretation specific params
  fasta = "$NGS_REFERENCE_DIR/ncbi_grch38_wholegenomefasta_genome.fa"
  vep_cache = "$NGS_REFERENCE_DIR/vep_cache/113/indexed/homo_sapiens_vep_113_GRCh38.tar.gz"

  // additional cio+ukb wgs pilot specific annotation settings
  mskcc = ""
  refseq_list = ""
  variantDBi = ""
  UKB_report = 1
  UKB_filter = 1

  // bwa params
  // run slower but save memory by using bwa (esp on indexing), not bwa2 (bwamem2)
  bwa_tool = 'bwa2'

}

report {
  enabled = true
  overwrite = true
  file = "${params.output_dir}/report.html"
}

timeline {
  enabled = true
  overwrite = true
  file = "${params.output_dir}/timeline.html"
}

trace {
  enabled = true
  overwrite = true
  file = "${params.output_dir}/trace.txt"
}

dag {
  enabled = true
  overwrite = true
  file = "${params.output_dir}/dag.dot"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
